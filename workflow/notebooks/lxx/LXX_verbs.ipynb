{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Hebrew to LXX verb mappings from the CATSS dataset\n",
    "\n",
    "The CATSS parallel dataset has been processed into JSON files in :\n",
    "https://github.com/codykingham/CATSS_parsers\n",
    "\n",
    "The dataset is not yet free of all parsing errors. But the overwhelming majority of \n",
    "lines in the dataset have been successfully parsed (greater than 99%). \n",
    "\n",
    "We will pick through this dataset to select some alignments of interest. At the \n",
    "moment we are most interested in verb alignments. Thus we will focus on the verbs.\n",
    "\n",
    "## Making the connections\n",
    "\n",
    "Several connections need to be made to sucessfully retrieve a verb\n",
    "alignment to the Hebrew:\n",
    "\n",
    "* Hebrew word in parallel dataset needs to successfully string-match\n",
    "with its BHSA equivalent (requires some normalizing to get them to \n",
    "match). This is done within a verse.\n",
    "* The verse of the Greek word needs to be sucessfully cross-referenced\n",
    "to its LXX verse reference. We can use the Copenhagen-Alliance's\n",
    "[verse mappings](https://github.com/Copenhagen-Alliance/versification-specification/tree/master/versification-mappings/standard-mappings) to\n",
    "accomplish this; the parallel dataset has its own way to indicate where the\n",
    "versification of Rahlfs differs from the BHS, but at the moment I do not\n",
    "trust its reliability.\n",
    "* the string of the Greek word within the selected parallel verse needs to be matched\n",
    "with the string of the word in the morphology dataset\n",
    "\n",
    "If these specifications are met, we have a match. The parallel will \n",
    "be stored in a dictionary format that will map the BHSA node number\n",
    "to all of the word data for a matching Greek verb.\n",
    "\n",
    "```\n",
    "{\n",
    "    3: {\n",
    "        \"utf8\": \"ἐποίησεν\",\n",
    "        \"trans\": \"E)POI/HSEN\",\n",
    "        \"typ\": \"verb\",\n",
    "        \"styp\": \"VAI\", \n",
    "        \"lexeme\": \"POIE/W\",\n",
    "        \"morph_code\": \"VAI.AAI3S\",\n",
    "        \"number\": \"sg\",\n",
    "        \"tense\": \"aorist\",\n",
    "        \"voice\": \"active\",\n",
    "        \"mood\": \"indc\",\n",
    "        \"person\": \"3\"\n",
    "    },\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bhsa node number can easily be used in Text-Fabric to get data on the word:\n",
    "\n",
    "```\n",
    "T.text(3) == 'בָּרָא'\n",
    "F.sp.v(3) == 'verb'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local commit\">TF-app:</b> <span title=\"#113c0687cfce3077734dac1844d244d20f4ace6f offline under ~/text-fabric-data\">~/text-fabric-data/annotation/app-bhsa/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.6 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/bhsa/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/phono/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"r1.2 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/parallels/tf/c</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.4.5</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa TF-app\">app-bhsa</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/0_home\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"BHSA feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Parallel Passages</b></summary><b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"~/text-fabric-data/etcbc/parallels/tf/c/crossref.tf\">crossref</a></i></b><br></details><details><summary><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b></summary><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/book.tf\">book</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/book@am.tf\">book@ll</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/chapter\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/code\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/code.tf\">code</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/det\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/det.tf\">det</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/domain\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/domain.tf\">domain</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/freq_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/freq_lex.tf\">freq_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/function\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/function.tf\">function</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_cons.tf\">g_cons</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_cons_utf8.tf\">g_cons_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_lex.tf\">g_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_lex_utf8.tf\">g_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_word.tf\">g_word</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/g_word_utf8.tf\">g_word_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gloss\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/label\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/label.tf\">label</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/language\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/language.tf\">language</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/lex_utf8.tf\">lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ls\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/ls.tf\">ls</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nametype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nametype.tf\">nametype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nme\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nme.tf\">nme</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/number\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/number.tf\">number</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/otype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pargr\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pargr.tf\">pargr</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pdp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pdp.tf\">pdp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pfm\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/pfm.tf\">pfm</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs.tf\">prs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_gn.tf\">prs_gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_nu.tf\">prs_nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/prs_ps.tf\">prs_ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere.tf\">qere</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_trailer.tf\">qere_trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_trailer_utf8.tf\">qere_trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/qere_utf8.tf\">qere_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rank_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/rank_lex.tf\">rank_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rela\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/rela.tf\">rela</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/sp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/st\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/st.tf\">st</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/tab\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/tab.tf\">tab</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/trailer.tf\">trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/trailer_utf8.tf\">trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/txt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/txt.tf\">txt</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/typ\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/typ.tf\">typ</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/uvf\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/uvf.tf\">uvf</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbe\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vbe.tf\">vbe</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vbs.tf\">vbs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/verse\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/voc_lex.tf\">voc_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/voc_lex_utf8.tf\">voc_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/mother\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/mother.tf\">mother</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/oslots\" title=\"~/text-fabric-data/etcbc/bhsa/tf/c/oslots.tf\">oslots</a></i></b><br></details><details><summary><b>Phonetic Transcriptions</b></summary><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/c/phono.tf\">phono</a><br><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/c/phono_trailer.tf\">phono_trailer</a><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".section {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--section);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--section:            hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import regex\n",
    "import collections\n",
    "from tf.app import use\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../../scripts/hebrew')\n",
    "from positions import PositionsTF\n",
    "\n",
    "# configure output files\n",
    "BHSA2LXX = Path('../../_private_/verb_data/bhsa2lxx.json')\n",
    "LXXVERSES = Path('../../_private_/verb_data/lxx_verses.csv')\n",
    "\n",
    "# get data locations for LXX and alignments\n",
    "github_dir = Path.home().joinpath('github')\n",
    "catss_repo = github_dir.joinpath('codykingham/CATSS_parsers')\n",
    "para_dir = catss_repo.joinpath('JSON/parallel') \n",
    "morph_dir = catss_repo.joinpath('JSON/morphology')\n",
    "\n",
    "# load the LXX data\n",
    "para_data = [\n",
    "    json.loads(file.read_text()) \n",
    "        for file in sorted(para_dir.glob('*.par.json'))\n",
    "]\n",
    "morph_data = [\n",
    "    json.loads(file.read_text())\n",
    "        for file in sorted(morph_dir.glob('*.mlxx.json'))\n",
    "]\n",
    "\n",
    "# get versification map for LXX and load it\n",
    "lxx_verse_map_file = github_dir.joinpath('copenhagen_alliance/versification-specification\\\n",
    "/versification-mappings/standard-mappings/lxx.json')\n",
    "lxx_verse_map = json.loads(lxx_verse_map_file.read_text())['mappedVerses']\n",
    "\n",
    "# load Text-Fabric (for Hebrew BHSA data)\n",
    "# and assign short-form variables for easy access to its methods\n",
    "bhsa = use('bhsa')\n",
    "api = bhsa.api\n",
    "F, E, T, L = api.F, api.E, api.T, api.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEN 1:1',\n",
       " [[['בראשׁית', []]], [], [['ἐν', []], ['ἀρχῇ', []]]],\n",
       " [[['ברא', []]], [], [['ἐποίησεν', []]]],\n",
       " [[['אלהים', []]], [], [['ὁ', []], ['θεὸς', []]]],\n",
       " [[['את', []], ['השׁמים', []]], [], [['τὸν', []], ['οὐρανὸν', []]]],\n",
       " [[['ואת', []], ['הארץ', []]], [], [['καὶ', []], ['τὴν', []], ['γῆν', []]]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEN 1:1',\n",
       " {'utf8': 'ἐν',\n",
       "  'trans': 'E)N',\n",
       "  'typ': 'prep',\n",
       "  'styp': 'P',\n",
       "  'lexeme': 'E)N',\n",
       "  'morph_code': 'P'},\n",
       " {'utf8': 'ἀρχῇ',\n",
       "  'trans': 'A)RXH=|',\n",
       "  'typ': 'noun',\n",
       "  'styp': 'N1',\n",
       "  'lexeme': 'A)RXH/',\n",
       "  'morph_code': 'N1.DSF',\n",
       "  'case': 'dat',\n",
       "  'number': 'sg',\n",
       "  'gender': 'f'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_data[0][0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DAG 2:1-49', 'DAN 2:1-49'),\n",
       " ('DAG 3:1-23', 'DAN 3:1-23'),\n",
       " ('DAG 3:91-97', 'DAN 3:24-30'),\n",
       " ('DAG 4:1-3', 'DAN 3:31-33'),\n",
       " ('DAG 4:4-37', 'DAN 4:1-34'),\n",
       " ('DAG 4:1-2', 'DAN 4:4-5'),\n",
       " ('DAG 5:1-30', 'DAN 5:1-30'),\n",
       " ('DAG 6:1-29', 'DAN 6:1-29'),\n",
       " ('DAG 7:1-28', 'DAN 7:1-28'),\n",
       " ('DAG 8:1-27', 'DAN 8:1-27')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lxx_verse_map.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Verse References\n",
    "\n",
    "The basis of all our connections will be on verse references. We will map the \n",
    "verse references to the USX schema: \n",
    "\n",
    "https://ubsicap.github.io/usx/vocabularies.html\n",
    "\n",
    "The CATSS parallel and morphology data have already been normalized with USX-style\n",
    "references. The only exception being those cases such as Joshua and Judges which have\n",
    "appended A or B (appended with an underscore).\n",
    "\n",
    "The USX verse references have mappings between LXX and MT, provided by the \n",
    "Copenhagen Alliance verse mappings:\n",
    "https://github.com/Copenhagen-Alliance/versification-specification/tree/master/versification-mappings/standard-mappings\n",
    "\n",
    "We will need to make some modifications to the versification for Ezra-Nehemiah,\n",
    "since the CATSS dataset follows the Greek division of the book into 2Esdras or \n",
    "Εσδρας β, and the Copenhagen mapping / USX use the Latin division for these books.\n",
    "For more on this, see https://en.wikipedia.org/wiki/Esdras#Naming_conventions\n",
    "\n",
    "The mappings we need to make are:\n",
    "* 2Esdras 1:1-10:44 == Ezra\n",
    "* 2Esdras 11:1-23:31 = Nehemiah\n",
    "\n",
    "NB: we only map relevant books (i.e. those with Hebrew attestations).\n",
    "\n",
    "We also create a dictionary, `mt2lxx_verse`, which contains 1-to-1 verse mappings\n",
    "from an MT verse reference to a LXX reference. \n",
    "\n",
    "NB: Copenhagen Alliance verse mappings start from 0 in the Psalms, presumably for the\n",
    "superscriptions (?). We do not have these verses in any of the datasets so we ignore\n",
    "0 verses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out Ezra/Ezdras mappings\n",
    "lxx_verse_map2 = {\n",
    "    v1:v2 for v1, v2 in lxx_verse_map.items() \n",
    "        if not regex.match('EZR|2ES', v1)\n",
    "}\n",
    "\n",
    "# add new mappings\n",
    "lxx_verse_map2.update({\n",
    "    '2ES 1:1-11': 'EZR 1:1-11',\n",
    "    '2ES 2:1-70': 'EZR 2:1-70',\n",
    "    '2ES 3:1-13': 'EZR 3:1-13',\n",
    "    '2ES 4:1-24': 'EZR 4:1-24',\n",
    "    '2ES 5:1-17': 'EZR 5:1-17',\n",
    "    '2ES 6:1-22': 'EZR 6:1-22',\n",
    "    '2ES 7:1-28': 'EZR 7:1-28',\n",
    "    '2ES 8:1-36': 'EZR 8:1-36',\n",
    "    '2ES 9:1-15': 'EZR 9:1-15',\n",
    "    '2ES 10:1-44': 'EZR 10:1-44',\n",
    "    \"2ES 11:1-11\": \"NEH 1:1-11\",\n",
    "    \"2ES 12:1-20\": \"NEH 2:1-20\",\n",
    "    \"2ES 13:1-38\": \"NEH 3:1-38\",\n",
    "    \"2ES 14:1-17\": \"NEH 4:1-17\",\n",
    "    \"2ES 15:1-19\": \"NEH 5:1-19\",\n",
    "    \"2ES 16:1-19\": \"NEH 6:1-19\",\n",
    "    \"2ES 17:1-72\": \"NEH 7:1-72\",\n",
    "    \"2ES 18:1-18\": \"NEH 8:1-18\",\n",
    "    \"2ES 19:1-37\": \"NEH 9:1-37\",\n",
    "    \"2ES 20:1-40\": \"NEH 10:1-40\",\n",
    "    \"2ES 21:1-36\": \"NEH 11:1-36\",\n",
    "    \"2ES 22:1-47\": \"NEH 12:1-47\",\n",
    "    \"2ES 23:1-31\": \"NEH 13:1-31\",\n",
    "})\n",
    "\n",
    "mt2lxx_versemap = {v:k for k,v in lxx_verse_map2.items()}\n",
    "\n",
    "def generate_verses(reference):\n",
    "    \"\"\"Split a reference range into individual references\"\"\"\n",
    "    reference = reference.replace(':0', ':1') # replace zero verses; don't know why they are there\n",
    "    book = reference.split()[0]\n",
    "    ch_vss = reference.split()[1]\n",
    "    ch = ch_vss.split(':')[0]\n",
    "    try:\n",
    "        vs_start, vs_end = ch_vss.split(':')[1].split('-')\n",
    "    except:\n",
    "        raise Exception(reference)\n",
    "    refs = []\n",
    "    for i in range(int(vs_start), int(vs_end)+1):\n",
    "        refs.append(f'{book} {ch}:{i}')\n",
    "    return refs\n",
    "\n",
    "# expand versemap to include every verse in between the ranges\n",
    "# so that a verse can be converted with a simple dict lookup\n",
    "mt2lxx_verse = {}\n",
    "\n",
    "for lxx_vss, mt_vss in lxx_verse_map2.items():\n",
    "    if '-' in lxx_vss and '-' in mt_vss:\n",
    "        lxx_refs = generate_verses(lxx_vss)\n",
    "        mt_refs = generate_verses(mt_vss)\n",
    "        mt2lxx_verse.update(zip(mt_refs, lxx_refs))\n",
    "    elif '-' not in lxx_vss and '-' not in mt_vss:\n",
    "        mt2lxx_verse[mt_vss] = lxx_vss\n",
    "    else:\n",
    "        raise Exception('NB: a not 1-to-1 mapping found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PSA 113:9'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "mt2lxx_verse['PSA 115:1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map BHSA verse references to USX abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhsa2usx = {\n",
    "    'Genesis': 'GEN',\n",
    "    'Exodus': 'EXO',\n",
    "    'Leviticus': 'LEV',\n",
    "    'Numbers': 'NUM',\n",
    "    'Deuteronomy': 'DEU',\n",
    "    'Joshua': 'JOS_B', # NB: going with B col for now\n",
    "    'Judges': 'JDG_A', # NB: going with A col for now\n",
    "    '1_Samuel': '1SA',\n",
    "    '2_Samuel': '2SA',\n",
    "    '1_Kings': '1KI',\n",
    "    '2_Kings': '2KI',\n",
    "    'Isaiah': 'ISA',\n",
    "    'Jeremiah': 'JER',\n",
    "    'Ezekiel': 'EZE',\n",
    "    'Hosea': 'HOS',\n",
    "    'Joel': 'JOL',\n",
    "    'Amos': 'AMO',\n",
    "    'Obadiah': 'OBA',\n",
    "    'Jonah': 'JON',\n",
    "    'Micah': 'MIC',\n",
    "    'Nahum': 'NAM',\n",
    "    'Habakkuk': 'HAB',\n",
    "    'Zephaniah': 'ZEP',\n",
    "    'Haggai': 'HAG',\n",
    "    'Zechariah': 'ZEC',\n",
    "    'Malachi': 'MAL',\n",
    "    'Psalms': 'PSA',\n",
    "    'Job': 'JOB',\n",
    "    'Proverbs': 'PRO',\n",
    "    'Ruth': 'RUT',\n",
    "    'Song_of_songs': 'SNG',\n",
    "    'Ecclesiastes': 'ECC',\n",
    "    'Lamentations': 'LAM',\n",
    "    'Esther': 'EST',\n",
    "    'Daniel': 'DAN',\n",
    "    'Ezra': 'EZR',\n",
    "    'Nehemiah': 'NEH',\n",
    "    '1_Chronicles': '1CH',\n",
    "    '2_Chronicles': '2CH',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map data to verse references\n",
    "\n",
    "Now we map the parallel and morphology data to verse references.\n",
    "These will serve as the primary basis for building the connections\n",
    "between the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "verse2para = {}\n",
    "verse2morph = {}\n",
    "\n",
    "for dataset, data_dict in [(para_data, verse2para), (morph_data, verse2morph)]:\n",
    "    for book in dataset:\n",
    "        for verse in book:\n",
    "            ref = verse[0]\n",
    "            verse_data = verse[1:]\n",
    "            data_dict[ref] = verse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[['בראשׁית', []]], [], [['ἐν', []], ['ἀρχῇ', []]]],\n",
       " [[['ברא', []]], [], [['ἐποίησεν', []]]],\n",
       " [[['אלהים', []]], [], [['ὁ', []], ['θεὸς', []]]],\n",
       " [[['את', []], ['השׁמים', []]], [], [['τὸν', []], ['οὐρανὸν', []]]],\n",
       " [[['ואת', []], ['הארץ', []]], [], [['καὶ', []], ['τὴν', []], ['γῆν', []]]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse2para['GEN 1:1'] # Now we can access the data by verse references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'utf8': 'ἐν',\n",
       "  'trans': 'E)N',\n",
       "  'typ': 'prep',\n",
       "  'styp': 'P',\n",
       "  'lexeme': 'E)N',\n",
       "  'morph_code': 'P'},\n",
       " {'utf8': 'ἀρχῇ',\n",
       "  'trans': 'A)RXH=|',\n",
       "  'typ': 'noun',\n",
       "  'styp': 'N1',\n",
       "  'lexeme': 'A)RXH/',\n",
       "  'morph_code': 'N1.DSF',\n",
       "  'case': 'dat',\n",
       "  'number': 'sg',\n",
       "  'gender': 'f'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse2morph['GEN 1:1'][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through BHSA candidates and build the connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_lxx_refs = set()\n",
    "\n",
    "def get_greek_morphology(word, ref):\n",
    "    \"\"\"Look up a word's morphology data based on its reference.\"\"\"\n",
    "    lxx_ref = mt2lxx_verse.get(ref, ref) # NB the MT to LXX verse mapping\n",
    "    \n",
    "    # no parallel in the Greek\n",
    "    # TODO: double check this status\n",
    "    if lxx_ref not in verse2morph:\n",
    "        missed_lxx_refs.add(ref)\n",
    "        return None\n",
    "    \n",
    "    for word_data in verse2morph[lxx_ref]:\n",
    "        if word_data['utf8'] == word:\n",
    "            word_data['LXX_verse'] = lxx_ref\n",
    "            return word_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utf8': 'ἀρχῇ',\n",
       " 'trans': 'A)RXH=|',\n",
       " 'typ': 'noun',\n",
       " 'styp': 'N1',\n",
       " 'lexeme': 'A)RXH/',\n",
       " 'morph_code': 'N1.DSF',\n",
       " 'case': 'dat',\n",
       " 'number': 'sg',\n",
       " 'gender': 'f',\n",
       " 'LXX_verse': 'GEN 1:1'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "ref = 'GEN 1:1'\n",
    "get_greek_morphology(verse2para[ref][0][2][1][0], ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ref = regex.compile(r'([A-Z0-9_]+) (\\d+)?:?(\\d+)')\n",
    "\n",
    "def update_verse(verse_ref, tc_notes):\n",
    "    \"\"\"Iterate through text-critical notation and update verse if necessary.\"\"\"\n",
    "    book, chapter, verse = match_ref.match(verse_ref).groups()\n",
    "    for note in tc_notes:\n",
    "        if note.isnumeric():\n",
    "            verse = note\n",
    "            break\n",
    "    return f'{book} {chapter}:{verse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "\tlinked: 62693 (91.0%)\n",
      "\tmissed: 6315 9.0%\n"
     ]
    }
   ],
   "source": [
    "bhsa2lxx = {}\n",
    "missed = []\n",
    "bad_mtverses = set()\n",
    "\n",
    "in_clause = lambda node1, node2: node2 in L.d(L.u(node1,'clause')[0], 'word')\n",
    "\n",
    "# begin making the connections\n",
    "for verb in F.pdp.s('verb'):\n",
    "    \n",
    "    P = PositionsTF(verb, 'clause', api).get\n",
    "    \n",
    "    # gather various candidates to attempt to match with the \n",
    "    # Hebrew parallel data stored in the LXX parallels dataset\n",
    "    possible_nodes = [(verb,)]\n",
    "    \n",
    "    # handle attached elements to normalize with LXX\n",
    "    if P(-1, 'lex') == 'W':\n",
    "        bhsa_nodes = (verb-1, verb)\n",
    "        possible_nodes.append(bhsa_nodes)\n",
    "    elif F.vt.v(verb).startswith('inf') and P(-1, 'pdp') == 'prep':        \n",
    "        bhsa_nodes = (verb-1, verb)\n",
    "        possible_nodes.append(bhsa_nodes)\n",
    "        if P(-2,'lex') == 'W':\n",
    "            bhsa_nodes = (P(-2),) + bhsa_nodes\n",
    "            possible_nodes.append(bhsa_nodes)\n",
    "    elif F.vt.v(verb).startswith('ptc') and P(-1, 'lex') == 'H':\n",
    "        bhsa_nodes = (verb-1, verb)\n",
    "        possible_nodes.append(bhsa_nodes)\n",
    "        \n",
    "    # assemble the strings\n",
    "    possible_strings = set()\n",
    "    for pnn in possible_nodes:\n",
    "        possible_strings.add(''.join(F.g_cons_utf8.v(n) for n in pnn))\n",
    "    \n",
    "    book, chapter, verse = T.sectionFromNode(verb)\n",
    "    usx_book = bhsa2usx[book]\n",
    "    if usx_book == 'OBA':\n",
    "        mt_ref = f'{usx_book} {verse}'\n",
    "    else:\n",
    "        mt_ref = f'{usx_book} {chapter}:{verse}'\n",
    "    \n",
    "    # attempt link to parallel data line on basis of Hebrew text\n",
    "    link = {}\n",
    "    try:\n",
    "        para_cols = verse2para[mt_ref]\n",
    "    except:\n",
    "        bad_mtverses.add(mt_ref)\n",
    "        continue\n",
    "        \n",
    "    for heb_colA, heb_colB, grk_col in para_cols :\n",
    "        \n",
    "        if not heb_colA or heb_colA[0] == 'PARSING_ERROR':\n",
    "            continue\n",
    "        \n",
    "        # attempt Hebrew connection to identify the right data line\n",
    "        heb_match = None\n",
    "        for word, tc_note in heb_colA:\n",
    "            if word in possible_strings:\n",
    "                heb_match = word\n",
    "                break\n",
    "          \n",
    "        if not heb_match:\n",
    "            continue\n",
    "            \n",
    "        # we have the right data line\n",
    "        # now attempt to make Greek connection\n",
    "        greek_match = None\n",
    "        if heb_match:\n",
    "            for greek_word, tc_note in grk_col:\n",
    "                \n",
    "                # modify reference\n",
    "                lxx_ref = update_verse(mt_ref, tc_note)\n",
    "                morph = get_greek_morphology(greek_word, lxx_ref)\n",
    "                if morph and morph['typ'] == 'verb':\n",
    "                    greek_match = morph\n",
    "                    break\n",
    "                    \n",
    "        # we've made a connection!\n",
    "        # save the data and move on\n",
    "        if greek_match:\n",
    "            #verb_data = (verb, mt_ref, F.g_cons_utf8.v(verb))\n",
    "            link[verb] = greek_match\n",
    "            \n",
    "    # record links and missed links\n",
    "    if link:\n",
    "        bhsa2lxx.update(link)\n",
    "    else:\n",
    "        missed.append((verb, mt_ref))\n",
    "        \n",
    "print(f'DONE')\n",
    "percent_done = round(len(bhsa2lxx) / (len(bhsa2lxx)+len(missed)), 2)*100\n",
    "percent_missed = round(len(missed) / (len(bhsa2lxx)+len(missed)), 2)*100\n",
    "print(f'\\tlinked: {len(bhsa2lxx)}', f'({percent_done}%)')\n",
    "print(f'\\tmissed: {len(missed)}', f'{percent_missed}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEU 4:25', 'EZE 34:27', 'EZE 44:18', 'JOS_B 22:34'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_mtverses # NB: these need to be fixed in the parallel database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verse2morph['GEN 3:17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for verb, ref in missed[:0]:\n",
    "    print(verb)\n",
    "    print(F.g_cons_utf8.v(verb))\n",
    "    print(ref)\n",
    "    for line in verse2para[ref]:\n",
    "        print('\\t', line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export LXX Data JSON\n",
    "with open(OUTFILE, 'w') as out:\n",
    "    json.dump(bhsa2lxx, out, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LXX_verse</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEN 1:1</td>\n",
       "      <td>ἐν ἀρχῇ ἐποίησεν ὁ θεὸς τὸν οὐρανὸν καὶ τὴν γῆν</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEN 1:2</td>\n",
       "      <td>ἡ δὲ γῆ ἦν ἀόρατος καὶ ἀκατασκεύαστος καὶ σκότ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEN 1:3</td>\n",
       "      <td>καὶ εἶπεν ὁ θεός γενηθήτω φῶς καὶ ἐγένετο φῶς</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEN 1:4</td>\n",
       "      <td>καὶ εἶδεν ὁ θεὸς τὸ φῶς ὅτι καλόν καὶ διεχώρισ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEN 1:5</td>\n",
       "      <td>καὶ ἐκάλεσεν ὁ θεὸς τὸ φῶς ἡμέραν καὶ τὸ σκότο...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LXX_verse                                               text\n",
       "0   GEN 1:1    ἐν ἀρχῇ ἐποίησεν ὁ θεὸς τὸν οὐρανὸν καὶ τὴν γῆν\n",
       "1   GEN 1:2  ἡ δὲ γῆ ἦν ἀόρατος καὶ ἀκατασκεύαστος καὶ σκότ...\n",
       "2   GEN 1:3      καὶ εἶπεν ὁ θεός γενηθήτω φῶς καὶ ἐγένετο φῶς\n",
       "3   GEN 1:4  καὶ εἶδεν ὁ θεὸς τὸ φῶς ὅτι καλόν καὶ διεχώρισ...\n",
       "4   GEN 1:5  καὶ ἐκάλεσεν ὁ θεὸς τὸ φῶς ἡμέραν καὶ τὸ σκότο..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble and export plain text verse data for LXX in a CSV\n",
    "rows = []\n",
    "for verse, words in verse2morph.items():\n",
    "    row = {}\n",
    "    row['LXX_verse'] = verse\n",
    "    row['text'] = ' '.join(w['utf8'] for w in words)\n",
    "    rows.append(row)\n",
    "    \n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30609, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(LXXVERSES, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
