# Snakemake Workflow for Gesenius Data 
# see https://snakemake.readthedocs.io

configfile: "../config/config.yaml"
tf_modules = [
    # order strategically to set priorities for features
    "/Users/cody/github/CambridgeSemiticsLab/time_collocations/data/bhsa/tf", 
    "/Users/cody/github/etcbc/bhsa/tf/c", 
    "/Users/cody/github/etcbc/genre_synvar/tf/c", 
    "/Users/cody/github/etcbc/valence/tf/c",
    "/Users/cody/github/etcbc/heads/tf/c",
]

# -- clone necessary data -- 

# Need to complete the gitclone rule begun below
# see: https://github.com/snakemake/snakemake/issues/350
# rule get_bhsa:
#     output:
#         directory(expand("~/github/{package}", package=bhsa_packages))
#     shell:
#         """
#         if [[! -d "{wildcards.package}" ]]; then
#             git clone https://github.com/{}    
#         """

# -- parse english data --
#GBI_datadir = "_private_/GBI_alignment/"
#rule parse_english_raw:
#    input:
#        niv_data=GBI_datadir+"niv84.ot.alignment.json",
#        esv_data=GBI_datadir+"esv.ot.alignment.json", 
#        bhsa_links=GBI_datadir+"bhsa2gbi.json"
#    output:
#        esv="_private_/verb_data/bhsa2esv.json",
#        niv="_private_/verb_data/bhsa2niv.json",
#        txt="_private_/GBI_alignment/verse2text.json",
#    script:
#        "scripts/english/parse/parse_english.py"
#
#        rule parse_english:

# -- generate samples --

rule get_samples:
    input:
        "/Users/cody/github/etcbc/bhsa/tf/c"
    output:
        directory("../results/samples"),
        expand("../results/samples/{verb}.json", verb=config["verb_forms"])
    script:
        "scripts/bhsa/get_samples.py"

# -- build csv tables --

# - BHSA -
csv_dir = "../results/csv"
bhsa_script="scripts/bhsa/build_bhsa_tables.py"
rule bhsa_tables:
    input:
        samples=expand("../results/samples/{verb}.json", verb=config["verb_forms"]),
        tf_mods=tf_modules,
        script=bhsa_script
    output:
        bhsa=temp(expand("../results/csv/{verb}/_bhsa_.csv", verb=config["verb_forms"])),
        bhsa_clrela=temp(expand("../results/csv/{verb}/_bhsa_clrela_.csv",verb=config["verb_forms"])),
    script:
        bhsa_script

# - English -
eng_script="scripts/english/build_eng_tables.py"
rule eng_tables:
    input:
        samples=expand("../results/samples/{verb}.json", verb=config["verb_forms"]),
        esv="_private_/verb_data/bhsa2esv.json",
        niv="_private_/verb_data/bhsa2niv.json",
        txt="_private_/GBI_alignment/verse2text.json",
        script=eng_script
    output: 
        eng=temp(expand("../results/csv/{verb}/_eng_.csv", verb=config["verb_forms"])),
        eng_text=temp(expand("../results/csv/{verb}/_eng_text_.csv", verb=config["verb_forms"]))
    script:
        eng_script

# - LXX -
lxx_script = "scripts/lxx/build_lxx_tables.py"
rule lxx_tables:
    input:
        samples=expand("../results/samples/{verb}.json", verb=config["verb_forms"]),
        lxx="_private_/verb_data/bhsa2lxx.json",
        script=lxx_script
    output:
        lxx=temp(expand("../results/csv/{verb}/_lxx_.csv", verb=config["verb_forms"])),
    script:
        lxx_script

# - apply some correction filters to the tables - 
qtl_loc = "../results/csv/qtl/"
qtl_corr_scr = "scripts/correct_qtl.py"
rule correct_qtl:
    input:
        qtl_corr_scr,
        bhsa=qtl_loc+"_bhsa_.csv",
        bhsa_clrela=qtl_loc+"_bhsa_clrela_.csv",
        eng=qtl_loc+"_eng_.csv",
        eng_text=qtl_loc+"_eng_text_.csv",
        lxx=qtl_loc+"_lxx_.csv"
    output:
        bhsa=qtl_loc+"bhsa.csv",
        bhsa_clrela=qtl_loc+"bhsa_clrela.csv",
        eng=qtl_loc+"eng.csv",
        eng_text=qtl_loc+"eng_text.csv",
        lxx=qtl_loc+"lxx.csv"
    script:
        qtl_corr_scr

# - run correlation analyses for qatal - 
qtl_analysis = "scripts/analysis/qtl/associations.py"
rule analyze_qtl:
    input:
        data_dir=qtl_loc,
        analyzers="scripts/analysis/analysis.py",
        script=qtl_analysis,
    output:
        dir=directory("../results/qtl/csv")
    script:
        qtl_analysis

qtl_vis="scripts/analysis/qtl/visualize.py"
rule visualize_qtl:
    input:
        results=rules.analyze_qtl.output.dir,
        visualizers="scripts/analysis/analysis_vis.py",
        script=qtl_vis,
        tablestyles="html/tables.css",
    output:
        dir=directory("../results/qtl/html")
    script:
        qtl_vis 
