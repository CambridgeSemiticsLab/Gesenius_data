{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build verb dataset from pre-compiled sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "from pathlib import Path\n",
    "from tf.fabric import Fabric\n",
    "from tf.app import use\n",
    "import pandas as pd\n",
    "\n",
    "# custom modules \n",
    "sys.path.append('../')\n",
    "import tf_tools\n",
    "from gbi_functions import id2ref\n",
    "from positions import PositionsTF\n",
    "\n",
    "# organize pathways / files\n",
    "PROJ_DIR = Path.home().joinpath('github/CambridgeSemiticsLab/Gesenius_data')\n",
    "VERB_DIR = PROJ_DIR.joinpath('data/_private_/verb_data')\n",
    "VERB_DIR_PUBLIC = PROJ_DIR.joinpath('data/_public_/verb_data')\n",
    "lxx_file = VERB_DIR.joinpath('bhsa2lxx.json')\n",
    "wlc_file = VERB_DIR.joinpath('bhsa2wlc.json')\n",
    "esv_file = VERB_DIR.joinpath('bhsa2esv.json')\n",
    "niv_file = VERB_DIR.joinpath('bhsa2niv.json')\n",
    "\n",
    "# load translation texts\n",
    "trans2text_file = PROJ_DIR.joinpath('data/_private_/GBI_alignment/verse2text.json')\n",
    "\n",
    "# load datasets\n",
    "bhsa2lxx = json.loads(lxx_file.read_text())\n",
    "bhsa2wlc = json.loads(wlc_file.read_text())\n",
    "bhsa2esv = json.loads(esv_file.read_text())\n",
    "bhsa2niv = json.loads(niv_file.read_text())\n",
    "trans2text = json.loads(trans2text_file.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 8.4.4\n",
      "Api reference : https://annotation.github.io/text-fabric/cheatsheet.html\n",
      "\n",
      "125 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "  6.39s All features loaded/computed - for details use loadLog()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local commit\">TF-app:</b> <span title=\"#113c0687cfce3077734dac1844d244d20f4ace6f offline under ~/text-fabric-data\">~/text-fabric-data/annotation/app-bhsa/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 8.4.4</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa TF-app\">app-bhsa</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/0_home\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"BHSA feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>etcbc/bhsa/tf/c/</b></summary><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//book.tf\">book</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//book@am.tf\">book@ll</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//code.tf\">code</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//domain.tf\">domain</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//function.tf\">function</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_cons.tf\">g_cons</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_cons_utf8.tf\">g_cons_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_lex.tf\">g_lex</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_lex_utf8.tf\">g_lex_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_word.tf\">g_word</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//g_word_utf8.tf\">g_word_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//label.tf\">label</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//language.tf\">language</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//lex_utf8.tf\">lex_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//number.tf\">number</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//pdp.tf\">pdp</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//qere.tf\">qere</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//qere_trailer.tf\">qere_trailer</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//qere_trailer_utf8.tf\">qere_trailer_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//qere_utf8.tf\">qere_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//rela.tf\">rela</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//trailer.tf\">trailer</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//trailer_utf8.tf\">trailer_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//txt.tf\">txt</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//typ.tf\">typ</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//voc_lex.tf\">voc_lex</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//voc_lex_utf8.tf\">voc_lex_utf8</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//mother.tf\">mother</a></i></b><br><b><i><a target=\"_blank\" href=\"https://github.com/etcbc/bhsa/tree/master/tf/c/\" title=\"~/github/etcbc/bhsa/tf/c//oslots.tf\">oslots</a></i></b><br></details><details><summary><b>etcbc/genre_synvar/tf/c/</b></summary><a target=\"_blank\" href=\"https://github.com/etcbc/genre_synvar/tree/master/tf/c/\" title=\"~/github/etcbc/genre_synvar/tf/c//genre.tf\">genre</a><br></details><details><summary><b>etcbc/valence/tf/c/</b></summary><a target=\"_blank\" href=\"https://github.com/etcbc/valence/tree/master/tf/c/\" title=\"~/github/etcbc/valence/tf/c//sense.tf\">sense</a><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".section {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--section);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--section:            hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load BHSA features with genre module\n",
    "locations = [\n",
    "    '~/github/etcbc/bhsa/tf/c', \n",
    "    '~/github/etcbc/genre_synvar/tf/c',\n",
    "    '~/github/etcbc/valence/tf/c'\n",
    "]\n",
    "TF = Fabric(locations)\n",
    "extra_features = '''\n",
    "domain txt ps gn \n",
    "nu genre sense\n",
    "mother sp\n",
    "'''\n",
    "features = tf_tools.standard_features + extra_features\n",
    "api = TF.load(features)\n",
    "bhsa = use('bhsa', api=api)\n",
    "F, E, T, L, Fs, = bhsa.api.F, bhsa.api.E, bhsa.api.T, bhsa.api.L, bhsa.api.Fs\n",
    "\n",
    "from clause_relas import in_dep_calc as clause_relator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thanks to Martijn Naaijer\n",
    "# for providing this handy list / code\n",
    "period_dict = {}\n",
    "ebh = ['Genesis', 'Exodus', 'Leviticus', 'Numbers', 'Deuteronomy', 'Joshua', 'Judges', '1_Samuel', '2_Samuel', '1_Kings', '2_Kings']\n",
    "lbh = ['Esther', 'Daniel', 'Ezra', 'Nehemiah', '1_Chronicles', '2_Chronicles']\n",
    "for book in ebh:\n",
    "    period_dict[book] = 'EBH'\n",
    "for book in lbh:\n",
    "    period_dict[book] = 'LBH'\n",
    "    \n",
    "def map_book_collections(label_and_ranges):\n",
    "    \"\"\"Apply a label to a range of books.\"\"\"\n",
    "    label_dict = {}\n",
    "    for label, book_start, book_end in label_and_ranges:\n",
    "        bs_node = T.nodeFromSection((book_start,))\n",
    "        be_node = T.nodeFromSection((book_end,))\n",
    "        in_between = list(range(bs_node, be_node+1))\n",
    "        whole_section = [bs_node] + in_between + [be_node]\n",
    "        for book_node in whole_section:\n",
    "            label_dict[T.sectionFromNode(book_node)[0]] = label \n",
    "    return label_dict\n",
    "\n",
    "tripart = map_book_collections([\n",
    "    ('Law', 'Genesis', 'Deuteronomy'), \n",
    "    ('Prophets', 'Joshua', 'Malachi'), \n",
    "    ('Writings', 'Psalms', '2_Chronicles')\n",
    "])\n",
    "\n",
    "subcollections = map_book_collections([\n",
    "    ('Samuel', '1_Samuel', '2_Samuel'),\n",
    "    ('Kings', '1_Kings', '2_Kings'),\n",
    "    ('Chronicles', '1_Chronicles', '2_Chronicles'),\n",
    "    ('Ezra-Neh', 'Ezra', 'Nehemiah'),\n",
    "    ('Twelve', 'Hosea', 'Malachi'),\n",
    "    ('Megilloth', 'Ruth', 'Esther'),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_re = re.compile(r'(.*)\\((.*)\\.(.*)\\.(.*)\\)')\n",
    "    \n",
    "def split_TAM(TAM_tag):\n",
    "    \"\"\"Split TAM tag and return parts as dict\"\"\"\n",
    "    tam_match = tam_re.match(TAM_tag)\n",
    "    if tam_match:\n",
    "        name, tense, aspect, modality = tam_match.groups()\n",
    "        return {\n",
    "            'tense': tense or np.nan,\n",
    "            'aspect': aspect or np.nan,\n",
    "            'modality': modality or np.nan,\n",
    "            'TAM': f'{tense}.{aspect}.{modality}',\n",
    "            'TAMtag': name.strip(),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'tense': np.nan,\n",
    "            'aspect': np.nan,\n",
    "            'modality': np.nan,\n",
    "            'TAM': np.nan,\n",
    "            'TAMtag': np.nan,\n",
    "        }\n",
    "    \n",
    "def get_verbform(node):\n",
    "    \"\"\"Remap BHSA verb tense values to custom values\n",
    "    \n",
    "    Args:\n",
    "        node: int representing BHSA node\n",
    "        preceding_words: list of preceding node ints\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Consider whether to keep preceding words\n",
    "    \n",
    "    tense_map = {\n",
    "            'impf': 'yqtl',\n",
    "            'perf': 'qtl',\n",
    "            'ptca': 'ptcp',\n",
    "    }\n",
    "    \n",
    "    bhsa_tense = F.vt.v(node)\n",
    "    verb_form = tense_map.get(bhsa_tense, bhsa_tense)\n",
    "    P = PositionsTF(node, 'clause', api)\n",
    "    \n",
    "    # adjust weqatal\n",
    "    if verb_form == 'qtl' and P.get(-1, 'lex') == 'W':\n",
    "        return 'wqtl'\n",
    "        \n",
    "    return verb_form\n",
    "\n",
    "def get_preceding_words(node, context='clause'):\n",
    "    \"\"\"Retrieves words from before a verb within a context\"\"\"\n",
    "    context_node = L.u(node, context)[0]\n",
    "    context_words = L.d(context_node, 'word')\n",
    "    prec_words = context_words[:context_words.index(node)]\n",
    "    return prec_words\n",
    "\n",
    "def join_on(nodes, jchar='_', default=np.nan):\n",
    "    \"\"\"Join words on a char and ensure they are pre/appended with that char.\n",
    "    \n",
    "    The pre/appending provides easy-to-match word boundaries.\n",
    "    \"\"\"\n",
    "    joined_string = f'{jchar}'.join(nodes)\n",
    "    if not joined_string:\n",
    "        return default\n",
    "    else:\n",
    "        return f'{jchar}{joined_string}{jchar}'\n",
    "\n",
    "def map_domain(node):\n",
    "    \"\"\"Map domains to be more permissive with Q\"\"\"\n",
    "    txt_type = F.txt.v(node)\n",
    "    if 'Q' in txt_type:\n",
    "        return 'Q'\n",
    "    else:\n",
    "        return txt_type[-1]\n",
    "    \n",
    "def tag_cl_verbform(clause_node):\n",
    "    \"\"\"Tag a verbform for a supplied clause.\"\"\"\n",
    "    verb = [\n",
    "        w for w in L.d(clause_node, 'word')\n",
    "            if F.pdp.v(w) == 'verb'\n",
    "    ]\n",
    "    if verb:\n",
    "        verb = verb[0]\n",
    "        prec_words = get_preceding_words(verb)\n",
    "        return get_verbform(verb)\n",
    "    else:\n",
    "        return 'Ø'\n",
    "    \n",
    "def get_relative_data(clause_lookup):\n",
    "    \"\"\"Retrieve data on a given relative clause, if it exists.\"\"\"\n",
    "    rel_dat = {}\n",
    "    if clause_lookup:\n",
    "        cl_atom = rel_dat['cl_atom'] = clause_lookup[0]\n",
    "        cl = rel_dat['cl'] = L.u(cl_atom, 'clause')[0]\n",
    "        rel_dat['typ'] = F.typ.v(cl_atom)\n",
    "        rel_dat['verb_type'] = tag_cl_verbform(cl_atom)\n",
    "        rel_dat['domain'] = map_domain(cl)\n",
    "        rel_dat['rela'] = clause_relator(cl)\n",
    "        rel_dat['txt'] = T.text(cl_atom)\n",
    "    return rel_dat\n",
    "\n",
    "cl_type_res = [\n",
    "    ('Way.*', 'W'),\n",
    "    ('^[xX].*', 'x'),\n",
    "    ('^W[xX].*', 'Wx'),\n",
    "    ('^W.*', 'W'),\n",
    "    ('^_W_.+', 'Wx'),\n",
    "    ('^_W_$', 'W'),\n",
    "]\n",
    "\n",
    "cl_type_res = [(re.compile(search), replace) for search, replace in cl_type_res]\n",
    "\n",
    "def search_replace_re(string, patterns, default=None):\n",
    "    \"\"\"Match a regex string\"\"\"\n",
    "    for search, replace in patterns:\n",
    "        if search.match(string):\n",
    "            return replace\n",
    "    return default\n",
    "\n",
    "def simplify_cl_type(clause_atom, prec_lexs):\n",
    "    \"\"\"Simplify a clausetype string into (x|X|Ø)Verb\"\"\"\n",
    "    \n",
    "    typ = F.typ.v(clause_atom)\n",
    "    \n",
    "    # apply to verbs missing X|x data\n",
    "    if typ in {'MSyn', 'CPen', 'Voct', 'InfC', 'Ellp', 'Ptcp'}:\n",
    "        return search_replace_re(prec_lexs, cl_type_res, 'Ø')\n",
    "        \n",
    "    # apply to other types\n",
    "    return search_replace_re(typ, cl_type_res, 'Ø')\n",
    "    \n",
    "def get_bhsa_data(node):\n",
    "    \"\"\"Compile all relevant BHSA data.\"\"\"\n",
    "    \n",
    "    # data on this clause itself\n",
    "    book, chapter, verse = T.sectionFromNode(node)\n",
    "    ref_string = f'{book} {chapter}:{verse}'\n",
    "    verse_node = L.u(node, 'verse')[0]\n",
    "    clause_atom = L.u(node, 'clause_atom')[0]\n",
    "    clause = L.u(node, 'clause')[0]\n",
    "    sent = L.u(node, 'sentence')[0]\n",
    "    clause_type = F.typ.v(clause)\n",
    "    preceding_words = get_preceding_words(node)\n",
    "    prec_lexes = join_on((F.lex.v(w) for w in preceding_words), default='Ø') \n",
    "    prec_pos = join_on((F.pdp.v(w) for w in preceding_words), default='Ø')\n",
    "    domain2 = map_domain(clause)\n",
    "    cl_type_simp = simplify_cl_type(clause_atom, prec_lexes)\n",
    "    \n",
    "    # build data on the mother/daughter clause\n",
    "    mo_data = get_relative_data(E.mother.f(clause_atom))\n",
    "    da_data = get_relative_data(E.mother.t(clause_atom))\n",
    "    \n",
    "    # collect preceding particles only\n",
    "    particle_types = {'advb', 'prep', 'conj', 'prde', 'prin', 'inj', 'inrg'}\n",
    "    prec_particles = join_on(\n",
    "        (F.lex.v(w) for w in preceding_words\n",
    "            if F.pdp.v(w) in particle_types)\n",
    "    , default='Ø') \n",
    "    \n",
    "    # map to verb form string\n",
    "    verbform = get_verbform(node)\n",
    "    \n",
    "    bhsa_data = {\n",
    "            'bhsa_node': node,\n",
    "            'ref': ref_string, \n",
    "            'book': book, \n",
    "            'book_super': subcollections.get(book, book),\n",
    "            'canon_part': tripart[book],\n",
    "            'text_full': F.g_word_utf8.v(node),\n",
    "            'text_plain': F.g_cons_utf8.v(node),\n",
    "            'lex': F.lex_utf8.v(node),\n",
    "            'lex_etcbc': F.lex.v(node),\n",
    "            'gloss': F.gloss.v(node),\n",
    "            'verb_form': verbform,\n",
    "            'stem': F.vs.v(node),\n",
    "            'person': F.ps.v(node),\n",
    "            'gender': F.gn.v(node),\n",
    "            'number': F.nu.v(node),\n",
    "            'clause_atom': T.text(clause_atom),\n",
    "            'clause': T.text(clause),\n",
    "            'sentence': T.text(sent),\n",
    "            'genre': F.genre.v(verse_node),\n",
    "            'domain': F.domain.v(clause),\n",
    "            'domain2': domain2,\n",
    "            'period': period_dict.get(book, ''),\n",
    "            'txt_type': F.txt.v(clause),\n",
    "            'clause_type': clause_type,\n",
    "            'cltype_simp': cl_type_simp,\n",
    "            'clause_rela': clause_relator(clause),\n",
    "            'mother_clause': mo_data.get('txt', np.nan),\n",
    "            'mother_type': mo_data.get('typ', np.nan),\n",
    "            'mother_verbtype': mo_data.get('verb_type', np.nan),\n",
    "            'mother_rela': mo_data.get('rela', np.nan),\n",
    "            'mother_domain2': mo_data.get('domain', np.nan),\n",
    "            'daught_clause': da_data.get('txt', np.nan),\n",
    "            'daught_type': da_data.get('typ', np.nan),\n",
    "            'daught_verbtype': da_data.get('verb_type', np.nan),\n",
    "            'daught_rela': da_data.get('rela', np.nan),\n",
    "            'daught_domain2': da_data.get('domain', np.nan),\n",
    "            'valence': F.sense.v(node),\n",
    "            'prec_lexes': prec_lexes,\n",
    "            'prec_pos': prec_pos,\n",
    "            'prec_part': prec_particles,\n",
    "    }\n",
    "    \n",
    "    return bhsa_data \n",
    "\n",
    "\n",
    "def build_dataset(bhsa_nodes):\n",
    "    \"\"\"Construct a dataset on select BHSA nodes.\"\"\"\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    for node in bhsa_nodes:\n",
    "        \n",
    "        str_node = str(node)\n",
    "        lxx_word = bhsa2lxx.get(str_node, {})\n",
    "        wlc_word = bhsa2wlc.get(str_node, {})\n",
    "        esv_word = bhsa2esv.get(str_node, {})\n",
    "        niv_word = bhsa2niv.get(str_node, {})\n",
    "        transs = [('esv', esv_word), ('niv', niv_word)]\n",
    "        \n",
    "        # add BHSA data\n",
    "        data_row = get_bhsa_data(node)\n",
    "\n",
    "        # add LXX data\n",
    "        data_row.update({\n",
    "            'lxx': lxx_word.get('utf8', np.nan),\n",
    "            'lxx_tense': lxx_word.get('tense', np.nan),\n",
    "            'lxx_voice': lxx_word.get('voice', np.nan),\n",
    "            'lxx_mood': lxx_word.get('mood', np.nan),\n",
    "            'lxx_person': lxx_word.get('person', np.nan),\n",
    "            'lxx_number': lxx_word.get('number', np.nan),\n",
    "        })\n",
    "        \n",
    "        if lxx_word:\n",
    "            data_row['lxx_tm'] = lxx_word['tense'] + ' ' + lxx_word['mood'] \n",
    "        else:\n",
    "            data_row['lxx_tm'] = np.nan\n",
    "        \n",
    "        # add TAM data from translations\n",
    "        for trans, tdata in transs:\n",
    "            ref_tuple = tuple(tdata.get('eng_ref', ''))\n",
    "            data_row[f'{trans}'] = tdata.get('words', np.nan)\n",
    "            data_row[f'{trans}_tags'] = tdata.get('tags', np.nan)\n",
    "            data_row[f'{trans}_VBtags'] = tdata.get('vb_tags', np.nan)\n",
    "            data_row[f'{trans}_verse'] = trans2text[trans].get(str(ref_tuple), np.nan)\n",
    "            \n",
    "            for tam_key, tam_data in split_TAM(tdata.get('TAM_cx', '')).items():\n",
    "                tam_key = f'{trans}_{tam_key}'\n",
    "                data_row[tam_key] = tam_data\n",
    "            \n",
    "            data_row[f'{trans}_TAMspan'] = tdata.get('TAM_span', np.nan)\n",
    "            \n",
    "        dataset.append(data_row)\n",
    "        \n",
    "    print(f'{len(dataset)} rows prepared!')\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def build_allverb_data(verb_nodes):\n",
    "    \"\"\"Build a dataset with generic BHSA nodes (including all verbs).\"\"\"\n",
    "    dataset = []\n",
    "    for node in verb_nodes:\n",
    "        dataset.append(\n",
    "            get_bhsa_data(node)\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "def xverb_collocations(verb_nodes, context='clause'):\n",
    "    \"\"\"For every verb tense, count lexemes in pre-verbal position.\"\"\"\n",
    "    \n",
    "    col_data = collections.defaultdict(lambda: collections.Counter())\n",
    "    for node in verb_nodes:\n",
    "        \n",
    "        lex = L.u(node, 'lex')[0]\n",
    "        verbt = F.vt.v(node)\n",
    "        preverb_words = get_preceding_words(node, context=context)\n",
    "        verbf = get_verbform(node)\n",
    "        \n",
    "        # build count\n",
    "        for w in preverb_words:\n",
    "            if F.lex.v(w).endswith('/'): # NB: skip nominal items\n",
    "                continue\n",
    "            col_data[verbf][F.lex.v(w)] += 1\n",
    "            \n",
    "    col_df = pd.DataFrame.from_dict(col_data, orient='index')\n",
    "            \n",
    "    return col_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qatal Dataset\n",
    "\n",
    "We build a dataset which is specific to qatal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20728 rows prepared!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14303, 67)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qatals = [\n",
    "    verb for verb in F.pdp.s('verb') \n",
    "        if F.vt.v(verb) == 'perf' \n",
    "        and F.language.v(verb) == 'Hebrew'\n",
    "]\n",
    "\n",
    "qatal_dataset = build_dataset(qatals)\n",
    "\n",
    "qatal_df = pd.DataFrame(qatal_dataset)\n",
    "\n",
    "\n",
    "# restrict to qatal forms\n",
    "qatal_df = qatal_df[qatal_df.verb_form == 'qtl']\n",
    "\n",
    "qatal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bhsa_node</th>\n",
       "      <th>ref</th>\n",
       "      <th>book</th>\n",
       "      <th>book_super</th>\n",
       "      <th>canon_part</th>\n",
       "      <th>text_full</th>\n",
       "      <th>text_plain</th>\n",
       "      <th>lex</th>\n",
       "      <th>lex_etcbc</th>\n",
       "      <th>gloss</th>\n",
       "      <th>...</th>\n",
       "      <th>niv</th>\n",
       "      <th>niv_tags</th>\n",
       "      <th>niv_VBtags</th>\n",
       "      <th>niv_verse</th>\n",
       "      <th>niv_tense</th>\n",
       "      <th>niv_aspect</th>\n",
       "      <th>niv_modality</th>\n",
       "      <th>niv_TAM</th>\n",
       "      <th>niv_TAMtag</th>\n",
       "      <th>niv_TAMspan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Genesis 1:1</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>בָּרָ֣א</td>\n",
       "      <td>ברא</td>\n",
       "      <td>ברא</td>\n",
       "      <td>BR&gt;[</td>\n",
       "      <td>create</td>\n",
       "      <td>...</td>\n",
       "      <td>created</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "      <td>PAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>PAST..IND</td>\n",
       "      <td>PAST</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>Genesis 1:2</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>הָיְתָ֥ה</td>\n",
       "      <td>היתה</td>\n",
       "      <td>היה</td>\n",
       "      <td>HJH[</td>\n",
       "      <td>be</td>\n",
       "      <td>...</td>\n",
       "      <td>was</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Now the earth was formless and empty , darknes...</td>\n",
       "      <td>PAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>PAST..IND</td>\n",
       "      <td>PAST</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Genesis 1:4</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>טֹ֑וב</td>\n",
       "      <td>טוב</td>\n",
       "      <td>טוב</td>\n",
       "      <td>VWB[</td>\n",
       "      <td>be good</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>Genesis 1:5</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>קָ֣רָא</td>\n",
       "      <td>קרא</td>\n",
       "      <td>קרא</td>\n",
       "      <td>QR&gt;[</td>\n",
       "      <td>call</td>\n",
       "      <td>...</td>\n",
       "      <td>he called</td>\n",
       "      <td>PRP|VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>God called the light “ day , ” and the darknes...</td>\n",
       "      <td>PAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>PAST..IND</td>\n",
       "      <td>PAST</td>\n",
       "      <td>called</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>Genesis 1:10</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>קָרָ֣א</td>\n",
       "      <td>קרא</td>\n",
       "      <td>קרא</td>\n",
       "      <td>QR&gt;[</td>\n",
       "      <td>call</td>\n",
       "      <td>...</td>\n",
       "      <td>he called</td>\n",
       "      <td>PRP|VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>God called the dry ground “ land , ” and the g...</td>\n",
       "      <td>PAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IND</td>\n",
       "      <td>PAST..IND</td>\n",
       "      <td>PAST</td>\n",
       "      <td>called</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bhsa_node           ref     book book_super canon_part text_full  \\\n",
       "0          3   Genesis 1:1  Genesis    Genesis        Law   בָּרָ֣א   \n",
       "1         15   Genesis 1:2  Genesis    Genesis        Law  הָיְתָ֥ה   \n",
       "2         47   Genesis 1:4  Genesis    Genesis        Law     טֹ֑וב   \n",
       "3         69   Genesis 1:5  Genesis    Genesis        Law    קָ֣רָא   \n",
       "4        172  Genesis 1:10  Genesis    Genesis        Law    קָרָ֣א   \n",
       "\n",
       "  text_plain  lex lex_etcbc    gloss  ...        niv niv_tags niv_VBtags  \\\n",
       "0        ברא  ברא      BR>[   create  ...    created      VBD        VBD   \n",
       "1       היתה  היה      HJH[       be  ...        was      VBD        VBD   \n",
       "2        טוב  טוב      VWB[  be good  ...        NaN      NaN        NaN   \n",
       "3        קרא  קרא      QR>[     call  ...  he called  PRP|VBD        VBD   \n",
       "4        קרא  קרא      QR>[     call  ...  he called  PRP|VBD        VBD   \n",
       "\n",
       "                                           niv_verse niv_tense niv_aspect  \\\n",
       "0  In the beginning God created the heavens and t...      PAST        NaN   \n",
       "1  Now the earth was formless and empty , darknes...      PAST        NaN   \n",
       "2                                                NaN       NaN        NaN   \n",
       "3  God called the light “ day , ” and the darknes...      PAST        NaN   \n",
       "4  God called the dry ground “ land , ” and the g...      PAST        NaN   \n",
       "\n",
       "  niv_modality    niv_TAM niv_TAMtag niv_TAMspan  \n",
       "0          IND  PAST..IND       PAST     created  \n",
       "1          IND  PAST..IND       PAST         was  \n",
       "2          NaN        NaN        NaN         NaN  \n",
       "3          IND  PAST..IND       PAST      called  \n",
       "4          IND  PAST..IND       PAST      called  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qatal_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! TO FIX !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bhsa_node</th>\n",
       "      <th>ref</th>\n",
       "      <th>book</th>\n",
       "      <th>book_super</th>\n",
       "      <th>canon_part</th>\n",
       "      <th>text_full</th>\n",
       "      <th>text_plain</th>\n",
       "      <th>lex</th>\n",
       "      <th>lex_etcbc</th>\n",
       "      <th>gloss</th>\n",
       "      <th>...</th>\n",
       "      <th>niv</th>\n",
       "      <th>niv_tags</th>\n",
       "      <th>niv_VBtags</th>\n",
       "      <th>niv_verse</th>\n",
       "      <th>niv_tense</th>\n",
       "      <th>niv_aspect</th>\n",
       "      <th>niv_modality</th>\n",
       "      <th>niv_TAM</th>\n",
       "      <th>niv_TAMtag</th>\n",
       "      <th>niv_TAMspan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1189</td>\n",
       "      <td>Genesis 3:1</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>אָמַ֣ר</td>\n",
       "      <td>אמר</td>\n",
       "      <td>אמר</td>\n",
       "      <td>&gt;MR[</td>\n",
       "      <td>say</td>\n",
       "      <td>...</td>\n",
       "      <td>Did say</td>\n",
       "      <td>VBD|VB</td>\n",
       "      <td>VBD|VB</td>\n",
       "      <td>Now the serpent was more crafty than any of th...</td>\n",
       "      <td>PRES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPV</td>\n",
       "      <td>PRES..IMPV</td>\n",
       "      <td>IMPV</td>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bhsa_node          ref     book book_super canon_part text_full  \\\n",
       "32       1189  Genesis 3:1  Genesis    Genesis        Law    אָמַ֣ר   \n",
       "\n",
       "   text_plain  lex lex_etcbc gloss  ...      niv niv_tags niv_VBtags  \\\n",
       "32        אמר  אמר      >MR[   say  ...  Did say   VBD|VB     VBD|VB   \n",
       "\n",
       "                                            niv_verse niv_tense niv_aspect  \\\n",
       "32  Now the serpent was more crafty than any of th...      PRES        NaN   \n",
       "\n",
       "   niv_modality     niv_TAM niv_TAMtag niv_TAMspan  \n",
       "32         IMPV  PRES..IMPV       IMPV         say  \n",
       "\n",
       "[1 rows x 67 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qatal_df[qatal_df.esv_TAM == 'PRES..IMPV'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Corrections\n",
    "\n",
    "There are some parsing problems with some past tense verbs and imperative verbs caused by the English parser. \n",
    "These can be detected by a lack of consensus amongst the various versions. For instance, in\n",
    "cases where an imperative is detected by the English parser, but that imperative is not\n",
    "reflected in the other English version, or that imperative is not corroborated by a future\n",
    "or imperative in the LXX.\n",
    "\n",
    "#### Lack of consesus is of interest\n",
    "\n",
    "To be sure, cases where there is a lack of consensus might also contain some properly tagged\n",
    "phrases, reflecting cases of true disagreement in the witnesses rather than a parsing mistake. \n",
    "Manual inspection has revealed that these cases are very few compared with the number of false\n",
    "positives however.\n",
    "\n",
    "#### Remedy\n",
    "\n",
    "To address these cases, we add a value to the data based on several manually configured\n",
    "boolean conditions: `safe`. Thus, if `safe == True`, the example in question has been filtered\n",
    "through these requirements. If the entire dataset is desired anyways, it can be retrieved by\n",
    "ignoring `safe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 nodes listed as unsafe...\n"
     ]
    }
   ],
   "source": [
    "bad_past_re = r'.*([Pp]ut|[Ss]et|[Cc]ut|[Ll]ay|[Cc]ast|[Ss]pread|[Ss]pit|[Rr]ead|rid)|darken'\n",
    "\n",
    "bad_past_esv = qatal_df[\n",
    "    (qatal_df.esv.str.match(bad_past_re, na=False))\n",
    "    & (qatal_df.esv_TAM == 'PAST..IND')\n",
    "    & (qatal_df.lxx_tm.str.match('.*(present|future)'))\n",
    "].bhsa_node\n",
    "\n",
    "bad_past_niv = qatal_df[\n",
    "    (qatal_df.niv.str.match(bad_past_re, na=False))\n",
    "    & (qatal_df.niv_TAM == 'PAST..IND')\n",
    "    & (qatal_df.lxx_tm.str.match('.*(present|future)'))\n",
    "].bhsa_node\n",
    "\n",
    "bad_impv = qatal_df[\n",
    "    (\n",
    "        (~qatal_df.niv_TAM.isin(['PRES..IMPV', 'FUT..IND', 'PRES..MOD', 'PRES..IND']) & (qatal_df.esv_TAM.isin(['PRES..IMPV'])))\n",
    "        | (qatal_df.niv_TAM.isin(['PRES..IMPV']) & (~qatal_df.esv_TAM.isin(['PRES..IMPV', 'FUT..IND', 'PRES..MOD', 'PRES..IND'])))\n",
    "    )\n",
    "    & (~qatal_df.lxx_tm.str.match('.*(future|impv)', na=False))\n",
    "].bhsa_node\n",
    "\n",
    "not_safe = [bad_past_esv, bad_past_niv, bad_impv]\n",
    "not_safe_nodes = set(n for iset in not_safe for n in iset)\n",
    "\n",
    "print(len(not_safe_nodes), 'nodes listed as unsafe...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "qatal_df['safe'] = ~qatal_df.bhsa_node.isin(not_safe_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14097, 68)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qatal_df[qatal_df.safe].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qatal_df.to_csv(VERB_DIR.joinpath('qatal_dataset.csv'), index=False)\n",
    "qatal_df.to_excel(VERB_DIR.joinpath('qatal_dataset.xlsx'), index=False, encoding='UTF-16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Verb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56955 ready for processing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bhsa_node</th>\n",
       "      <th>ref</th>\n",
       "      <th>book</th>\n",
       "      <th>book_super</th>\n",
       "      <th>canon_part</th>\n",
       "      <th>text_full</th>\n",
       "      <th>text_plain</th>\n",
       "      <th>lex</th>\n",
       "      <th>lex_etcbc</th>\n",
       "      <th>gloss</th>\n",
       "      <th>...</th>\n",
       "      <th>mother_domain2</th>\n",
       "      <th>daught_clause</th>\n",
       "      <th>daught_type</th>\n",
       "      <th>daught_verbtype</th>\n",
       "      <th>daught_rela</th>\n",
       "      <th>daught_domain2</th>\n",
       "      <th>valence</th>\n",
       "      <th>prec_lexes</th>\n",
       "      <th>prec_pos</th>\n",
       "      <th>prec_part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Genesis 1:1</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>בָּרָ֣א</td>\n",
       "      <td>ברא</td>\n",
       "      <td>ברא</td>\n",
       "      <td>BR&gt;[</td>\n",
       "      <td>create</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ</td>\n",
       "      <td>WXQt</td>\n",
       "      <td>qtl</td>\n",
       "      <td>Main</td>\n",
       "      <td>?</td>\n",
       "      <td>d-</td>\n",
       "      <td>_B_R&gt;CJT/_</td>\n",
       "      <td>_prep_subs_</td>\n",
       "      <td>_B_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>Genesis 1:2</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>הָיְתָ֥ה</td>\n",
       "      <td>היתה</td>\n",
       "      <td>היה</td>\n",
       "      <td>HJH[</td>\n",
       "      <td>be</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום</td>\n",
       "      <td>NmCl</td>\n",
       "      <td>Ø</td>\n",
       "      <td>Main</td>\n",
       "      <td>?</td>\n",
       "      <td>--</td>\n",
       "      <td>_W_H_&gt;RY/_</td>\n",
       "      <td>_conj_art_subs_</td>\n",
       "      <td>_W_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Genesis 1:2</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>מְרַחֶ֖פֶת</td>\n",
       "      <td>מרחפת</td>\n",
       "      <td>רחף</td>\n",
       "      <td>RXP[</td>\n",
       "      <td>shake</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>_W_RWX/_&gt;LHJM/_</td>\n",
       "      <td>_conj_subs_subs_</td>\n",
       "      <td>_W_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Genesis 1:3</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>יֹּ֥אמֶר</td>\n",
       "      <td>יאמר</td>\n",
       "      <td>אמר</td>\n",
       "      <td>&gt;MR[</td>\n",
       "      <td>say</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>יְהִ֣י אֹ֑ור</td>\n",
       "      <td>ZYqX</td>\n",
       "      <td>yqtl</td>\n",
       "      <td>Main</td>\n",
       "      <td>Q</td>\n",
       "      <td>--</td>\n",
       "      <td>_W_</td>\n",
       "      <td>_conj_</td>\n",
       "      <td>_W_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>Genesis 1:3</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>Law</td>\n",
       "      <td>יְהִ֣י</td>\n",
       "      <td>יהי</td>\n",
       "      <td>היה</td>\n",
       "      <td>HJH[</td>\n",
       "      <td>be</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>--</td>\n",
       "      <td>Ø</td>\n",
       "      <td>Ø</td>\n",
       "      <td>Ø</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bhsa_node          ref     book book_super canon_part   text_full  \\\n",
       "0          3  Genesis 1:1  Genesis    Genesis        Law     בָּרָ֣א   \n",
       "1         15  Genesis 1:2  Genesis    Genesis        Law    הָיְתָ֥ה   \n",
       "2         27  Genesis 1:2  Genesis    Genesis        Law  מְרַחֶ֖פֶת   \n",
       "3         33  Genesis 1:3  Genesis    Genesis        Law    יֹּ֥אמֶר   \n",
       "4         35  Genesis 1:3  Genesis    Genesis        Law      יְהִ֣י   \n",
       "\n",
       "  text_plain  lex lex_etcbc   gloss  ... mother_domain2  \\\n",
       "0        ברא  ברא      BR>[  create  ...            NaN   \n",
       "1       היתה  היה      HJH[      be  ...              ?   \n",
       "2      מרחפת  רחף      RXP[   shake  ...              ?   \n",
       "3       יאמר  אמר      >MR[     say  ...              ?   \n",
       "4        יהי  היה      HJH[      be  ...              N   \n",
       "\n",
       "                           daught_clause daught_type daught_verbtype  \\\n",
       "0  וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ         WXQt             qtl   \n",
       "1        וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום         NmCl               Ø   \n",
       "2                                    NaN         NaN             NaN   \n",
       "3                          יְהִ֣י אֹ֑ור         ZYqX            yqtl   \n",
       "4                                    NaN         NaN             NaN   \n",
       "\n",
       "  daught_rela daught_domain2 valence       prec_lexes          prec_pos  \\\n",
       "0        Main              ?      d-       _B_R>CJT/_       _prep_subs_   \n",
       "1        Main              ?      --       _W_H_>RY/_   _conj_art_subs_   \n",
       "2         NaN            NaN    None  _W_RWX/_>LHJM/_  _conj_subs_subs_   \n",
       "3        Main              Q      --              _W_            _conj_   \n",
       "4         NaN            NaN      --                Ø                 Ø   \n",
       "\n",
       "  prec_part  \n",
       "0       _B_  \n",
       "1       _W_  \n",
       "2       _W_  \n",
       "3       _W_  \n",
       "4         Ø  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_verbs = []\n",
    "\n",
    "for verb in F.pdp.s('verb'):\n",
    "    if F.language.v(verb) != 'Hebrew':\n",
    "        continue\n",
    "    if F.vt.v(verb) in {'perf', 'impf', 'wayq', 'ptca', 'ptcp'}:\n",
    "        all_verbs.append(verb)\n",
    "        \n",
    "print(len(all_verbs), 'ready for processing')\n",
    "\n",
    "all_verbs_data = build_allverb_data(all_verbs)\n",
    "\n",
    "\n",
    "av_df = pd.DataFrame(all_verbs_data)\n",
    "\n",
    "av_df.to_csv(VERB_DIR_PUBLIC.joinpath('allverb_bhsa.csv'), index=False)\n",
    "\n",
    "av_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>lex_etcbc</th>\n",
       "      <th>B</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>KJ</th>\n",
       "      <th>L</th>\n",
       "      <th>&gt;CR</th>\n",
       "      <th>HNH</th>\n",
       "      <th>L&gt;</th>\n",
       "      <th>MN</th>\n",
       "      <th>&gt;P</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;BD[</th>\n",
       "      <th>LHN</th>\n",
       "      <th>CLL=[</th>\n",
       "      <th>&gt;JKKH</th>\n",
       "      <th>BWZ[</th>\n",
       "      <th>&lt;WT[</th>\n",
       "      <th>CLC[</th>\n",
       "      <th>HJK</th>\n",
       "      <th>RC&lt;[</th>\n",
       "      <th>CXV=[</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb_form</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qtl</th>\n",
       "      <td>744.0</td>\n",
       "      <td>3795</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>2974.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1827.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptcp</th>\n",
       "      <td>96.0</td>\n",
       "      <td>1328</td>\n",
       "      <td>1511.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yqtl</th>\n",
       "      <td>1144.0</td>\n",
       "      <td>6134</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>557.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wayq</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wqtl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lex_etcbc       B      W       H      KJ      L     >CR    HNH      L>     MN  \\\n",
       "verb_form                                                                       \n",
       "qtl         744.0   3795  1326.0  1838.0  371.0  2974.0  182.0  1827.0  325.0   \n",
       "ptcp         96.0   1328  1511.0   246.0   85.0   358.0  367.0    78.0   51.0   \n",
       "yqtl       1144.0   6134  1540.0  1122.0  557.0   970.0   50.0  2746.0  503.0   \n",
       "wayq          0.0  14974     0.0     0.0    0.0     0.0    0.0     0.0    0.0   \n",
       "wqtl          0.0   6425     0.0     0.0    0.0     0.0    0.0     0.0    0.0   \n",
       "\n",
       "lex_etcbc    >P  ...  <BD[  LHN  CLL=[  >JKKH  BWZ[  <WT[  CLC[  HJK  RC<[  \\\n",
       "verb_form        ...                                                         \n",
       "qtl        32.0  ...   0.0  0.0    0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "ptcp        6.0  ...   0.0  0.0    0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "yqtl       51.0  ...   1.0  2.0    1.0    4.0   1.0   1.0   1.0  2.0   1.0   \n",
       "wayq        0.0  ...   0.0  0.0    0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "wqtl        0.0  ...   0.0  0.0    0.0    0.0   0.0   0.0   0.0  0.0   0.0   \n",
       "\n",
       "lex_etcbc  CXV=[  \n",
       "verb_form         \n",
       "qtl          0.0  \n",
       "ptcp         0.0  \n",
       "yqtl         1.0  \n",
       "wayq         0.0  \n",
       "wqtl         0.0  \n",
       "\n",
       "[5 rows x 463 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_col_df = xverb_collocations(all_verbs)\n",
    "av_col_df = av_col_df.fillna(0)\n",
    "av_col_df.index.name = 'verb_form'\n",
    "av_col_df.columns.name = 'lex_etcbc'\n",
    "av_col_df.to_csv(VERB_DIR_PUBLIC.joinpath('xverb_lexcollocations.csv'))\n",
    "av_col_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
